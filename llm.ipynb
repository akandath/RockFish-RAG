{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347812a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708ed48a",
   "metadata": {},
   "source": [
    "# LLM Layer (RAG Chatbot)\n",
    "\n",
    "This notebook sets up the final **LLM layer** for our Retrieval-Augmented Generation (RAG) chatbot. \n",
    "\n",
    "✅ It connects to a local Chroma DB containing vector embeddings of the documents.  \n",
    "✅ Uses a lightweight open-source model (**GROQ**) for natural language generation.  \n",
    "✅ Combines both for a **conversational chatbot** that:\n",
    "- Retrieves relevant document chunks from Chroma DB.\n",
    "- Generates contextual answers with LLM.\n",
    "- Maintains conversational memory for a natural chat experience.\n",
    "\n",
    "This is the last step of our RAG pipeline, enabling us to answer user questions interactively and conversationally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chroma retriever\n",
    "persist_directory = \"chroma_db\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "chroma_db = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "retriever = chroma_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dffd953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq API function\n",
    "import requests\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "def get_groq_completion(prompt: str) -> str:\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {GROQ_API_KEY}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"deepseek-r1-distill-llama-70b\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a helpful assistant. Provide clear, concise, and professional answers. The other thing to consider is potential buyers might interact with you so you should subtly sell the product without being too pushy. \"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    response = requests.post(\n",
    "        \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "        headers=headers,\n",
    "        json=data\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    result = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "    if \"<think>\" in result and \"</think>\" in result:\n",
    "        result = result.split(\"</think>\")[-1].strip()\n",
    "\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final context-aware QA function\n",
    "def answer_with_context(question: str, top_k: int = 10):\n",
    "    top_chunks: list[Document] = retriever.get_relevant_documents(question, top_k=top_k)\n",
    "    combined_context = \"\\n\\n\".join(chunk.page_content for chunk in top_chunks)\n",
    "\n",
    "    prompt = (\n",
    "        f\"Context:\\n{combined_context}\\n\\n\"\n",
    "        f\"Question: {question}\\n\\n\"\n",
    "        f\"Answer concisely and professionally.\"\n",
    "    )\n",
    "    answer = get_groq_completion(prompt)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b6db42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " Certainly! Integrating the Rockfish API into your existing stack is straightforward. Here’s a concise guide to get you started:\n",
      "\n",
      "### Step 1: Install the Rockfish SDK\n",
      "Install the Rockfish SDK using your preferred package manager:\n",
      "\n",
      "```bash\n",
      "# For Python (using pip)\n",
      "pip install rockfish-sdk\n",
      "\n",
      "# For JavaScript (using npm)\n",
      "npm install @rockfish/sdk\n",
      "\n",
      "# For Java (using Maven)\n",
      "<dependency>\n",
      "    <groupId>com.rockfish</groupId>\n",
      "    <artifactId>rockfish-sdk</artifactId>\n",
      "    <version>1.0.0</version>\n",
      "</dependency>\n",
      "```\n",
      "\n",
      "### Step 2: Initialize the Rockfish Client\n",
      "Use your API key to initialize the client:\n",
      "\n",
      "```python\n",
      "from rockfish import RockfishClient\n",
      "\n",
      "# Initialize the client with your API key\n",
      "client = RockfishClient(api_key=\"your_api_key_here\")\n",
      "```\n",
      "\n",
      "### Step 3: Create a Configuration File\n",
      "Create a Rockfish config file (e.g., `rockfish_config.json`) with your API credentials and settings:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"profiles\": {\n",
      "        \"default\": {\n",
      "            \"api_key\": \"your_api_key_here\",\n",
      "            \"api_url\": \"https://api.rockfish.ai\",\n",
      "            \"project\": \"your_project_name\",\n",
      "            \"organization\": \"your_organization_name\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "### Step 4: Make API Requests\n",
      "Use the client to make API requests:\n",
      "\n",
      "```python\n",
      "# Example: Make a POST request to the /api endpoint\n",
      "response = client.post(\"/api\", json={\"data\": \"your_data_here\"})\n",
      "\n",
      "# Print the response\n",
      "print(response.json())\n",
      "```\n",
      "\n",
      "### Step 5: Explore More Endpoints\n",
      "Refer to the Rockfish API documentation to explore additional endpoints and features.\n",
      "\n",
      "### Need Further Assistance?\n",
      "If you need more detailed examples or have specific questions about integration, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "question = \"How do I integrate the Rockfish API in my existing stack? give me clear and concise code examples. Imagine that I have the API key\"\n",
    "answer = answer_with_context(question)\n",
    "print(\"\\nAnswer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c06002",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What types of data can it create? Can it create data for a specific industry?\"\n",
    "answer = answer_with_context(question)\n",
    "print(\"\\nAnswer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "363fb20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " **Research Behind the Product:**  \n",
      "The research focuses on synthetic data generation, data adaptability, recommendation engines, and data privacy, addressing challenges in sparse data environments and fraud detection across industries like e-commerce, healthtech, and life sciences.\n",
      "\n",
      "**Technology Behind the Product:**  \n",
      "Built on proprietary technology from Carnegie Mellon University, the platform utilizes advanced machine learning algorithms, neural architectures, and specialized data encoding techniques to adapt to various data schemas and types.\n",
      "\n",
      "**Main Researchers:**  \n",
      "While specific names aren't provided, the team includes leading researchers and engineers from Carnegie Mellon University, known for their expertise in AI and data science, with multiple patents filed reflecting their innovative contributions.\n"
     ]
    }
   ],
   "source": [
    "question = \"what is the research behind the product? What is the technology behind the product? who are the main researchers behind the product?\"\n",
    "answer = answer_with_context(question)\n",
    "print(\"\\nAnswer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4208da",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"can you cite some technicalities of the product from a research standpoint? What are the main technical features of the product?\"\n",
    "answer = answer_with_context(question)\n",
    "print(\"\\nAnswer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfaf59ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " Our product has received positive feedback from customers across various industries, who appreciate its ability to handle real-time operational data. Here’s a structured overview of customer sentiments and how to assess the product's effectiveness:\n",
      "\n",
      "1. **E-commerce Industry**: Customers value the product for its real-time alerts when a SKU is out of stock or when a new product launches, enabling quick restocking and maintaining customer satisfaction.\n",
      "\n",
      "2. **Healthtech and Life Sciences**: In these fields, where data is often scarce, customers commend the product's ability to manage sparse data, facilitating informed decision-making despite limited information.\n",
      "\n",
      "3. **Fraud Detection**: Businesses in finance and e-commerce appreciate the product's enhanced fraud detection capabilities, which help reduce fraudulent transactions and build customer trust.\n",
      "\n",
      "To determine if the product creates useful data, consider the following outcomes:\n",
      "- **Reduced Stockouts**: The product's alerts help businesses restock promptly, minimizing stockouts.\n",
      "- **Improved Fraud Detection**: It identifies fraudulent transactions more effectively, saving costs and enhancing security.\n",
      "- **Better Decision-Making**: In data-scarce environments, the product aids in making informed decisions, demonstrating its utility.\n",
      "\n",
      "These outcomes indicate that the product generates useful data, solving real-world problems across industries.\n"
     ]
    }
   ],
   "source": [
    "question = \"what do you customers say about the product? Give concrete examples and cite the sources. How do I know whether the product creates useful data?\"\n",
    "answer = answer_with_context(question)\n",
    "print(\"\\nAnswer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ff2c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " Thank you for considering Rockfish Solution. We understand that choosing the right product is a significant decision. Rockfish stands out as a unique and differentiated solution in the synthetic data space, backed by a team of experts dedicated to innovation and support. Our strong partner ecosystem and collaborative approach ensure that we can address your specific needs effectively. If you're ready to explore how Rockfish can benefit your business, we're here to guide you through the next steps. Let's discuss how we can support your goals together.\n"
     ]
    }
   ],
   "source": [
    "question = \"I am on the fence about buying the product. Can you convince me to buy it? Why rockfish?\"\n",
    "answer = answer_with_context(question)\n",
    "print(\"\\nAnswer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddafad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rf_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
